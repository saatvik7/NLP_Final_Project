@article{Ghosh-Muresan,
  author    = {Debanjan Ghosh and
               Avijit Vajpayee and
               Smaranda Muresan},
  title     = {A Report on the 2020 Sarcasm Detection Shared Task},
  journal   = {CoRR},
  volume    = {abs/2005.05814},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.05814},
  eprinttype = {arXiv},
  eprint    = {2005.05814},
  timestamp = {Thu, 14 May 2020 16:56:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2005-05814.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{van-hee-etal-2018-semeval,
    title = "{S}em{E}val-2018 Task 3: Irony Detection in {E}nglish Tweets",
    author = "Van Hee, Cynthia  and
      Lefever, Els  and
      Hoste, V{\'e}ronique",
    booktitle = "Proceedings of The 12th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S18-1005",
    doi = "10.18653/v1/S18-1005",
    pages = "39--50",
    abstract = "This paper presents the first shared task on irony detection: given a tweet, automatic natural language processing systems should determine whether the tweet is ironic (Task A) and which type of irony (if any) is expressed (Task B). The ironic tweets were collected using irony-related hashtags (i.e. {\#}irony, {\#}sarcasm, {\#}not) and were subsequently manually annotated to minimise the amount of noise in the corpus. Prior to distributing the data, hashtags that were used to collect the tweets were removed from the corpus. For both tasks, a training corpus of 3,834 tweets was provided, as well as a test set containing 784 tweets. Our shared tasks received submissions from 43 teams for the binary classification Task A and from 31 teams for the multiclass Task B. The highest classification scores obtained for both subtasks are respectively F1= 0.71 and F1= 0.51 and demonstrate that fine-grained irony classification is much more challenging than binary irony detection.",
}

@inproceedings{abu-farha,
title = "Overview of the WANLP 2021 Shared Task on Sarcasm and Sentiment Detection in Arabic",
abstract = "This paper provides an overview of the WANLP 2021 shared task on sarcasm and sentiment detection in Arabic. The shared task has two subtasks: sarcasm detection (subtask 1) and sentiment analysis (subtask 2). This shared task aims to promote and bring attention to Arabic sarcasm detection, which is crucial to improve the performance in other tasks such as sentiment analysis. The dataset used in this shared task, namely ArSarcasm-v2, consists of 15,548 tweets labelled for sarcasm, sentiment and dialect. We received 27 and 22 submissions for subtasks 1 and 2 respectively. Most of the approaches relied on using and fine-tuning pre-trained language models such as AraBERT and MARBERT. The top achieved results for the sarcasm detection and sentiment analysis tasks were 0.6225 F1-score and 0.748F1PN respectively",
author = "{Abu Farha}, Ibrahim and Wajdi Zaghouani and Walid Magdy",
year = "2021",
month = apr,
day = "19",
language = "English",
isbn = "978-1-954085-09-1",
pages = "296--305",
booktitle = "Proceedings of the Sixth Arabic Natural Language Processing Workshop",
publisher = "Association for Computational Linguistics (ACL)",
note = "The Sixth Arabic Natural Language Processing Workshop, WANLP 2021 ; Conference date: 19-04-2021 Through 19-04-2021",
url = "https://sites.google.com/view/wanlp2021",
}

@book{Salton:86,
  added-at = {2008-03-08T17:00:56.000+0100},
  address = {New York, NY, USA},
  author = {Salton, G. and McGill, M. J.},
  biburl = {https://www.bibsonomy.org/bibtex/258802c19b067ac210904abfd5e4f6ba7/brightbyte},
  interhash = {915a0ae4fcba0f00f4af65a8355b9f82},
  intrahash = {58802c19b067ac210904abfd5e4f6ba7},
  isbn = {0070544840},
  keywords = {classic information retrieval},
  publisher = {McGraw-Hill, Inc.},
  timestamp = {2009-01-23T09:58:50.000+0100},
  title = {Introduction to Modern Information Retrieval},
  year = 1986
}

@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{hazarika,
  author    = {Devamanyu Hazarika and
               Soujanya Poria and
               Sruthi Gorantla and
               Erik Cambria and
               Roger Zimmermann and
               Rada Mihalcea},
  title     = {{CASCADE:} Contextual Sarcasm Detection in Online Discussion Forums},
  journal   = {CoRR},
  volume    = {abs/1805.06413},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.06413},
  eprinttype = {arXiv},
  eprint    = {1805.06413},
  timestamp = {Mon, 13 Aug 2018 16:46:11 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-06413.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{oprea,
  author    = {Silviu Oprea and
               Walid Magdy},
  title     = {Exploring Author Context for Detecting Intended vs Perceived Sarcasm},
  journal   = {CoRR},
  volume    = {abs/1910.11932},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.11932},
  eprinttype = {arXiv},
  eprint    = {1910.11932},
  timestamp = {Thu, 31 Oct 2019 14:02:26 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-11932.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{opreaiSarcasm,
  author    = {Silviu Oprea and
               Walid Magdy},
  title     = {iSarcasm: {A} Dataset of Intended Sarcasm},
  journal   = {CoRR},
  volume    = {abs/1911.03123},
  year      = {2019},
  url       = {http://arxiv.org/abs/1911.03123},
  eprinttype = {arXiv},
  eprint    = {1911.03123},
  timestamp = {Mon, 11 Nov 2019 18:38:09 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1911-03123.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ghosh2020report,
  title={A report on the 2020 sarcasm detection shared task},
  author={Ghosh, Debanjan and Vajpayee, Avijit and Muresan, Smaranda},
  journal={arXiv preprint arXiv:2005.05814},
  year={2020}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@inproceedings{10.5555/1870568.1870582,
author = {Davidov, Dmitry and Tsur, Oren and Rappoport, Ari},
title = {Semi-Supervised Recognition of Sarcastic Sentences in Twitter and Amazon},
year = {2010},
isbn = {9781932432831},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Sarcasm is a form of speech act in which the speakers convey their message in an implicit way. The inherently ambiguous nature of sarcasm sometimes makes it hard even for humans to decide whether an utterance is sarcastic or not. Recognition of sarcasm can benefit many sentiment analysis NLP applications, such as review summarization, dialogue systems and review ranking systems.In this paper we experiment with semi-supervised sarcasm identification on two very different data sets: a collection of 5.9 million tweets collected from Twitter, and a collection of 66000 product reviews from Amazon. Using the Mechanical Turk we created a gold standard sample in which each sentence was tagged by 3 annotators, obtaining F-scores of 0.78 on the product reviews dataset and 0.83 on the Twitter dataset. We discuss the differences between the datasets and how the algorithm uses them (e.g., for the Amazon dataset the algorithm makes use of structured information). We also discuss the utility of Twitter #sarcasm hashtags for the task.},
booktitle = {Proceedings of the Fourteenth Conference on Computational Natural Language Learning},
pages = {107–116},
numpages = {10},
location = {Uppsala, Sweden},
series = {CoNLL '10}
}

@INPROCEEDINGS{Veale10detectingironic,
    author = {Tony Veale and Yanfen Hao},
    title = {Detecting ironic intent in creative comparisons},
    booktitle = {In: Proceedings of 19th European conference on artificial intelligence—ECAI 2010},
    year = {2010},
    pages = {765--770},
    publisher = {IOS Press}
}

@inproceedings{Ghosh2015SarcasticON,
  title={Sarcastic or Not: Word Embeddings to Predict the Literal or Sarcastic Meaning of Words},
  author={Debanjan Ghosh and Weiwei Guo and Smaranda Muresan},
  booktitle={EMNLP},
  year={2015}
}

@inproceedings{Wallace2014HumansRC,
  title={Humans Require Context to Infer Ironic Intent (so Computers Probably do, too)},
  author={Byron C. Wallace and Do Kook Choe and Laura Kertz and Eugene Charniak},
  booktitle={ACL},
  year={2014}
}

@article{10.1145/3124420,
author = {Joshi, Aditya and Bhattacharyya, Pushpak and Carman, Mark J.},
title = {Automatic Sarcasm Detection: A Survey},
year = {2017},
issue_date = {November 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3124420},
doi = {10.1145/3124420},
abstract = {Automatic sarcasm detection is the task of predicting sarcasm in text. This is a crucial step to sentiment analysis, considering prevalence and challenges of sarcasm in sentiment-bearing text. Beginning with an approach that used speech-based features, automatic sarcasm detection has witnessed great interest from the sentiment analysis community. This article is a compilation of past work in automatic sarcasm detection. We observe three milestones in the research so far: semi-supervised pattern extraction to identify implicit sentiment, use of hashtag-based supervision, and incorporation of context beyond target text. In this article, we describe datasets, approaches, trends, and issues in sarcasm detection. We also discuss representative performance values, describe shared tasks, and provide pointers to future work, as given in prior works. In terms of resources to understand the state-of-the-art, the survey presents several useful illustrations—most prominently, a table that summarizes past papers along different dimensions such as the types of features, annotation techniques, and datasets used.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {73},
numpages = {22},
keywords = {sentiment, Sarcasm, opinion, sentiment analysis, sarcasm detection}
}

@inproceedings{khattri-etal-2015-sentiment,
    title = "Your Sentiment Precedes You: Using an author{'}s historical tweets to predict sarcasm",
    author = "Khattri, Anupam  and
      Joshi, Aditya  and
      Bhattacharyya, Pushpak  and
      Carman, Mark",
    booktitle = "Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = sep,
    year = "2015",
    address = "Lisboa, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W15-2905",
    doi = "10.18653/v1/W15-2905",
    pages = "25--30",
}

@inproceedings{bamman2015contextualized,
  title={Contextualized sarcasm detection on twitter},
  author={Bamman, David and Smith, Noah A},
  booktitle={Ninth international AAAI conference on web and social media},
  year={2015}
}

@article{Muresan,
author = {Muresan, Smaranda and González-Ibáñez, Roberto and Ghosh, Debanjan and Wacholder, Nina},
year = {2016},
month = {11},
pages = {n/a-n/a},
title = {Identification of nonliteral language in social media: A case study on sarcasm},
volume = {67},
journal = {Journal of the Association for Information Science and Technology},
doi = {10.1002/asi.23624}
}

@InProceedings{maas-EtAl:2011:ACL-HLT2011,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}